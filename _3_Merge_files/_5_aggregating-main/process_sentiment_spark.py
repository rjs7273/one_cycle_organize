from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_date, avg
import os

# âœ… Spark ì„¸ì…˜ ì„¤ì •
spark = SparkSession.builder.appName("SentimentAggregation").getOrCreate()

# âœ… íšŒì‚¬ ë¦¬ìŠ¤íŠ¸ ì •ì˜
companies = ["samsung", "apple", "nvidia", "skhynix"]  # í•„ìš”í•œ ê¸°ì—… ì¶”ê°€ ê°€ëŠ¥

# âœ… ì›ë³¸ ë°ì´í„° & ì €ì¥ í´ë” ê²½ë¡œ ì„¤ì •
raw_data_path = "D:/Project/"
processed_data_path = "./data/processed/"

# âœ… ëª¨ë“  ê¸°ì—… ë°ì´í„° ì²˜ë¦¬
for company in companies:
    file_path = f"file:///{raw_data_path}{company}_predict_bert.csv"  # Sparkì—ì„œ ë¡œì»¬ íŒŒì¼ ì½ê¸° í˜•ì‹ ì ìš©
    
    print(f"ğŸ” Checking file: {file_path}")  # ë””ë²„ê¹…ìš© ì¶œë ¥
    
    local_file_path = os.path.join(raw_data_path, f"{company}_predict_bert.csv")  # ë¡œì»¬ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ìš©
    if not os.path.exists(local_file_path):
        print(f"âš ï¸ {company} ë°ì´í„° íŒŒì¼ ì—†ìŒ: {local_file_path}")
        continue

    # ğŸ“Œ CSV íŒŒì¼ ë¡œë“œ
    df = spark.read.option("header", True).option("inferSchema", True).csv(file_path)

    # ğŸ“Œ ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
    df = df.withColumn("date", to_date(col("time")))  # "time" ì»¬ëŸ¼ì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œ

    # ğŸ“Œ ë‚ ì§œë³„ ê°ì • ë¹„ìœ¨ í‰ê·  ê³„ì‚°
    df_daily = df.groupBy("date").agg(
        avg("prob_fear").alias("fear_ratio"),
        avg("prob_neutral").alias("neutral_ratio"),
        avg("prob_greed").alias("greed_ratio")
    )

    # ğŸ“Œ ê²°ê³¼ í™•ì¸ (ìƒìœ„ 5ê°œ ë°ì´í„°)
    print(f"âœ… {company} ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ:")
    df_daily.show(5)

    # ğŸ“Œ Pandas ë³€í™˜ í›„ CSV ì €ì¥
    os.makedirs(processed_data_path, exist_ok=True)  # í´ë” ì—†ìœ¼ë©´ ìƒì„±
    output_file = os.path.join(processed_data_path, f"{company}_daily_sentiment.csv")
    df_daily.toPandas().to_csv(output_file, index=False, encoding="utf-8-sig")

    print(f"ğŸ’¾ {company} ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_file}")

print("ğŸ¯ ëª¨ë“  ê¸°ì—… ê°ì • ë¶„ì„ ì™„ë£Œ!")
